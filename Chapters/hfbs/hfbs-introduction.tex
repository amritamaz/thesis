Virtual reality (VR) devices are becoming widely available, from camera rigs for video capture~\cite{googlejump, facebooksurround}, to headsets for immersive viewing~\cite{oculusrift, gearvr}.
Real-time rendering of 3D-360$\degree$ video can enable a wide range of VR applications, from live sports and concert broadcasting to telepresence.
While the domains of VR video content capture and viewing are growing more popular, no system is capable of producing 3D-360$\degree$ VR videos in real time as of yet.
Camera rigs like Google Jump and Facebook Surround~\cite{googlejump} allow users to capture standard 2D video and render it as 3D-360$\degree$ videos.
Real-time VR video capture, coupled with immersive headsets like Google Daydream, Oculus Rift, or Samsung Gear VR~\cite{googlecardboard, gearvr, oculusrift}, can enable a wide range of applications, from live sports and concert broadcasting to tele-presence.

The Google Jump camera rig~\cite{googlejump} is one example of a commodity VR video capture device, using $16$ cameras to capture high-resolution (4K-1080p) overlapping video streams of a 360$\degree$ scene.
The collected video is used to estimate edge-aware flow fields, which are composited into a stereoscopic 3D-360$\degree$ video.
A key portion of this processing pipeline, flow estimation, is constructed around the \emph{bilateral solver}, a fast and edge-aware algorithm that combines simple bilateral filters with domain-specific optimization problems~\cite{BarronPoole2016}.
This flow estimation algorithm consumes the majority of the processing time, despite using one of the fastest existing algorithms across thousands of cores~\cite{googlejump}.


In this chapter, we introduce a new algorithm for this flow estimation problem, the hardware-friendly bilateral solver (HFBS).
HFBS achieves significant speedups over the bilateral solver with little accuracy loss.
While Barron and Poole's bilateral solver~\cite{BarronPoole2016} is challenging to parallelize on modern hardware, our ``hardware-friendly'' algorithm can be easily parallelized on GPUs and field-programmable gate arrays (FPGAs).
To demonstrate, we design a scalable FPGA-based hardware accelerator for HFBS, employing specialized memory layout and reduced-precision fixed-point computation to achieve real-time results.
Compared to the original bilateral solver, HFBS is 4$\times$ faster on a CPU, 32$\times$ faster on a GPU, and 50$\times$ faster on an FPGA.
We evaluate the accuracy of HFBS on the depth superresolution task and show that our algorithm is faster than every more accurate algorithm, and more accurate than any faster algorithm.

This chapter makes two contributions: an algorithm for hardware-friendly bilateral solving, and a fixed-function FPGA accelerator implementing HFBS.
To achieve fast performance while maintaining accuracy, we take a hardware-software codesign approach where both the algorithm and hardware substrate are developed in tandem.
Our algorithm modifies the original bilateral solver to ensure memory access is predictable and therefore fast, and performs optimization using preconditioned gradient descent with momentum to reduce global communication and enable parallel execution.
Our hardware accelerator explores fixed-point arithmetic and bilateral-grid-specialized memory layout to process large-resolution bilateral grids in a scalable way in real time.
Many of these performance optimizations are codependent, and we evaluate performance of the algorithm and hardware together to illustrate our results.
Our algorithm and accelerator design make it more practical to generate real-time VR video from camera rigs, either locally at the capture device, or in the cloud to accelerate large-scale video processing.
